{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3268689e",
   "metadata": {
    "papermill": {
     "duration": 0.010013,
     "end_time": "2023-03-12T14:39:17.261738",
     "exception": false,
     "start_time": "2023-03-12T14:39:17.251725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine Tuning YOLOV3 To Detect Masks From Scratch\n",
    "\n",
    "In this netbook we will fine tune yolov3 model to detect masks from scratch using tensorflow and keras.We will learn a lot, such as encoding and decoding data and netout and how to use yolo algorithm to prepare data using image segmentation into grids methode,and how to make the output of the model a list of arrays with different shapes(detect small and big objects) also we will learn how to use weights of a specifique class from yolov3 as a starting point.\n",
    "I used Face Mask Detection dataset (https://www.kaggle.com/datasets/andrewmvd/face-mask-detection) and the accuracy was too good when trying the real time mask detection\n",
    "\n",
    "If this Kernel helped you in any way, give it an upvote (such that I can increasy my online self-esteem...)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2853d6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:17.281590Z",
     "iopub.status.busy": "2023-03-12T14:39:17.280437Z",
     "iopub.status.idle": "2023-03-12T14:39:21.640126Z",
     "shell.execute_reply": "2023-03-12T14:39:21.639133Z"
    },
    "papermill": {
     "duration": 4.372325,
     "end_time": "2023-03-12T14:39:21.642641",
     "exception": false,
     "start_time": "2023-03-12T14:39:17.270316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b7e2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:21.662112Z",
     "iopub.status.busy": "2023-03-12T14:39:21.660504Z",
     "iopub.status.idle": "2023-03-12T14:39:44.224469Z",
     "shell.execute_reply": "2023-03-12T14:39:44.223240Z"
    },
    "papermill": {
     "duration": 22.575725,
     "end_time": "2023-03-12T14:39:44.227035",
     "exception": false,
     "start_time": "2023-03-12T14:39:21.651310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\r\n",
      "  Downloading roboflow-0.2.34-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from roboflow) (1.15.0)\r\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /opt/conda/lib/python3.7/site-packages (from roboflow) (4.5.4.60)\r\n",
      "Collecting requests-toolbelt\r\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.7/site-packages (from roboflow) (1.21.6)\r\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from roboflow) (6.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.7/site-packages (from roboflow) (1.26.13)\r\n",
      "Requirement already satisfied: certifi==2022.12.7 in /opt/conda/lib/python3.7/site-packages (from roboflow) (2022.12.7)\r\n",
      "Collecting wget\r\n",
      "  Downloading wget-3.2.zip (10 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from roboflow) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from roboflow) (1.4.3)\r\n",
      "Collecting chardet==4.0.0\r\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from roboflow) (9.1.1)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.7/site-packages (from roboflow) (0.21.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from roboflow) (2.28.1)\r\n",
      "Collecting idna==2.10\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting cycler==0.10.0\r\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from roboflow) (3.5.3)\r\n",
      "Collecting pyparsing==2.4.7\r\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from roboflow) (4.64.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->roboflow) (22.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->roboflow) (4.33.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->roboflow) (2.1.0)\r\n",
      "Building wheels for collected packages: wget\r\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=231ce8a8a9efd72bd0488d1bbe1816115945dbe8c0784f5f99de603bbb357295\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\r\n",
      "Successfully built wget\r\n",
      "Installing collected packages: wget, pyparsing, idna, cycler, chardet, requests-toolbelt, roboflow\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.0.9\r\n",
      "    Uninstalling pyparsing-3.0.9:\r\n",
      "      Successfully uninstalled pyparsing-3.0.9\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.3\r\n",
      "    Uninstalling idna-3.3:\r\n",
      "      Successfully uninstalled idna-3.3\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.11.0\r\n",
      "    Uninstalling cycler-0.11.0:\r\n",
      "      Successfully uninstalled cycler-0.11.0\r\n",
      "  Attempting uninstall: chardet\r\n",
      "    Found existing installation: chardet 5.0.0\r\n",
      "    Uninstalling chardet-5.0.0:\r\n",
      "      Successfully uninstalled chardet-5.0.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\r\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.11.0 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\r\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.44 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed chardet-4.0.0 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 requests-toolbelt-0.10.1 roboflow-0.2.34 wget-3.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed5aa82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:44.249552Z",
     "iopub.status.busy": "2023-03-12T14:39:44.249223Z",
     "iopub.status.idle": "2023-03-12T14:39:51.374930Z",
     "shell.execute_reply": "2023-03-12T14:39:51.373905Z"
    },
    "papermill": {
     "duration": 7.978645,
     "end_time": "2023-03-12T14:39:52.217068",
     "exception": false,
     "start_time": "2023-03-12T14:39:44.238423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in mask-detection-with-high-performcance-4 to darknet: 100% [31597521 / 31597521] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to mask-detection-with-high-performcance-4 in darknet:: 100%|██████████| 2936/2936 [00:00<00:00, 3480.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is Face Mask dataset from kaggle converted into yolo format with txt files using roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"NY3PWalwsDPYmaOHhqlJ\")\n",
    "project = rf.workspace(\"abdelhakim-workspace\").project(\"mask-detection-with-high-performcance\")\n",
    "dataset = project.version(4).download(\"darknet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08190709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:52.681796Z",
     "iopub.status.busy": "2023-03-12T14:39:52.681402Z",
     "iopub.status.idle": "2023-03-12T14:39:52.686272Z",
     "shell.execute_reply": "2023-03-12T14:39:52.685196Z"
    },
    "papermill": {
     "duration": 0.211472,
     "end_time": "2023-03-12T14:39:52.688806",
     "exception": false,
     "start_time": "2023-03-12T14:39:52.477334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/working/mask-detection-with-high-performcance-4/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c73b521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:53.093444Z",
     "iopub.status.busy": "2023-03-12T14:39:53.093074Z",
     "iopub.status.idle": "2023-03-12T14:39:53.100442Z",
     "shell.execute_reply": "2023-03-12T14:39:53.099374Z"
    },
    "papermill": {
     "duration": 0.212034,
     "end_time": "2023-03-12T14:39:53.102862",
     "exception": false,
     "start_time": "2023-03-12T14:39:52.890828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def is_supported(x):\n",
    "    try:\n",
    "        byte_img = tf.io.read_file(x)\n",
    "        img = tf.io.decode_jpeg(byte_img)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def remove_invalid_images(dataset):\n",
    "    return dataset.filter((lambda x: tf.py_function(func=is_supported, inp=[x], Tout=tf.bool))) # logical_not is a fuction that returns the negation, In other words, if is_supported returns True, this lambda function will return False, and if is_supported returns False, this lambda function will return True.\n",
    "\n",
    "def get_annotation_filename(image_filename):\n",
    "    # Get the filename without the extension\n",
    "    #\".\" correspond à un point,\n",
    "    # \"[^/.]\" signifie n'importe quel caractère qui n'est ni un point ni un slash,\n",
    "    # \"+\" signifie une ou plusieurs répétitions du caractère précédent,\n",
    "    # \"$\" correspond à la fin de la chaîne de caractères.\n",
    "    base_filename = tf.strings.regex_replace(image_filename, '\\\\.[^/.]+$', '')\n",
    "    # Append the .txt extension to the filename\n",
    "    annotation_filename = tf.strings.join([base_filename, '.txt'])\n",
    "    return annotation_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b81cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:53.559320Z",
     "iopub.status.busy": "2023-03-12T14:39:53.558954Z",
     "iopub.status.idle": "2023-03-12T14:39:56.452178Z",
     "shell.execute_reply": "2023-03-12T14:39:56.451230Z"
    },
    "papermill": {
     "duration": 3.097448,
     "end_time": "2023-03-12T14:39:56.454811",
     "exception": false,
     "start_time": "2023-03-12T14:39:53.357363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_paths = tf.data.Dataset.list_files(train_path + '/*.jpg', shuffle=False)\n",
    "images_paths = remove_invalid_images(images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1386ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:56.869749Z",
     "iopub.status.busy": "2023-03-12T14:39:56.868698Z",
     "iopub.status.idle": "2023-03-12T14:39:56.920164Z",
     "shell.execute_reply": "2023-03-12T14:39:56.919226Z"
    },
    "papermill": {
     "duration": 0.26596,
     "end_time": "2023-03-12T14:39:56.922624",
     "exception": false,
     "start_time": "2023-03-12T14:39:56.656664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_paths = images_paths.map(get_annotation_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e03def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:57.327339Z",
     "iopub.status.busy": "2023-03-12T14:39:57.326616Z",
     "iopub.status.idle": "2023-03-12T14:39:59.411218Z",
     "shell.execute_reply": "2023-03-12T14:39:59.410214Z"
    },
    "papermill": {
     "duration": 2.291498,
     "end_time": "2023-03-12T14:39:59.413824",
     "exception": false,
     "start_time": "2023-03-12T14:39:57.122326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for file in annotations_paths:\n",
    "    coords = []\n",
    "    with open(file.numpy()) as f:\n",
    "        lines = f.read()\n",
    "        lines = lines.split('\\n')\n",
    "        lines = [l.split(' ') for l in lines]\n",
    "        for n,line in enumerate(lines):\n",
    "            number = []\n",
    "            for i,l in enumerate(line):\n",
    "                if lines[n][i]:\n",
    "                    number.append(float(lines[n][i]))\n",
    "            if number:\n",
    "                coords.append(number)\n",
    "    annotations.append(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef41c6c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:39:59.860127Z",
     "iopub.status.busy": "2023-03-12T14:39:59.859777Z",
     "iopub.status.idle": "2023-03-12T14:39:59.865723Z",
     "shell.execute_reply": "2023-03-12T14:39:59.864715Z"
    },
    "papermill": {
     "duration": 0.25404,
     "end_time": "2023-03-12T14:39:59.867948",
     "exception": false,
     "start_time": "2023-03-12T14:39:59.613908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.cast(tf.image.resize(img,[416,416]),tf.int32)\n",
    "    img = tf.reshape(img,[416,416,3])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7bacd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:00.268147Z",
     "iopub.status.busy": "2023-03-12T14:40:00.267794Z",
     "iopub.status.idle": "2023-03-12T14:40:00.333056Z",
     "shell.execute_reply": "2023-03-12T14:40:00.332105Z"
    },
    "papermill": {
     "duration": 0.268176,
     "end_time": "2023-03-12T14:40:00.335425",
     "exception": false,
     "start_time": "2023-03-12T14:40:00.067249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = images_paths.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c1f9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:00.740284Z",
     "iopub.status.busy": "2023-03-12T14:40:00.739926Z",
     "iopub.status.idle": "2023-03-12T14:40:00.760119Z",
     "shell.execute_reply": "2023-03-12T14:40:00.759264Z"
    },
    "papermill": {
     "duration": 0.223468,
     "end_time": "2023-03-12T14:40:00.762064",
     "exception": false,
     "start_time": "2023-03-12T14:40:00.538596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a66c0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:01.164896Z",
     "iopub.status.busy": "2023-03-12T14:40:01.164052Z",
     "iopub.status.idle": "2023-03-12T14:40:01.172792Z",
     "shell.execute_reply": "2023-03-12T14:40:01.171873Z"
    },
    "papermill": {
     "duration": 0.211836,
     "end_time": "2023-03-12T14:40:01.175017",
     "exception": false,
     "start_time": "2023-03-12T14:40:00.963181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (416, 416, 3), types: tf.float64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed30df",
   "metadata": {
    "papermill": {
     "duration": 0.202744,
     "end_time": "2023-03-12T14:40:01.620774",
     "exception": false,
     "start_time": "2023-03-12T14:40:01.418030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b831b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:02.024761Z",
     "iopub.status.busy": "2023-03-12T14:40:02.024384Z",
     "iopub.status.idle": "2023-03-12T14:40:02.029278Z",
     "shell.execute_reply": "2023-03-12T14:40:02.028342Z"
    },
    "papermill": {
     "duration": 0.208445,
     "end_time": "2023-03-12T14:40:02.031192",
     "exception": false,
     "start_time": "2023-03-12T14:40:01.822747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inverse of sigmoid function\n",
    "def _logit(x):\n",
    "    x = np.clip(x, 1e-9, 1 - 1e-9)  # clip values to (0, 1) range to solve -inf problème\n",
    "    return np.log(x / (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d764d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:02.432699Z",
     "iopub.status.busy": "2023-03-12T14:40:02.432002Z",
     "iopub.status.idle": "2023-03-12T14:40:02.437073Z",
     "shell.execute_reply": "2023-03-12T14:40:02.436110Z"
    },
    "papermill": {
     "duration": 0.208109,
     "end_time": "2023-03-12T14:40:02.439015",
     "exception": false,
     "start_time": "2023-03-12T14:40:02.230906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c174ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:02.980934Z",
     "iopub.status.busy": "2023-03-12T14:40:02.980256Z",
     "iopub.status.idle": "2023-03-12T14:40:02.998290Z",
     "shell.execute_reply": "2023-03-12T14:40:02.997440Z"
    },
    "papermill": {
     "duration": 0.361477,
     "end_time": "2023-03-12T14:40:03.000760",
     "exception": false,
     "start_time": "2023-03-12T14:40:02.639283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_annotations(annotation, nb_classes, anchors, net_h, net_w):\n",
    "    nb_bbox = 3\n",
    "    shape = [(13, 13, nb_bbox, nb_classes+5), (26, 26 ,nb_bbox, nb_classes+5), (52, 52, nb_bbox, nb_classes+5)] # +5 for the bbox and objness\n",
    "    train_netout = [np.ones(s)*1e-9 for s in shape] # we are making values 1e-9 that is a very small number because we will apply _logit function to elements ,so they should't be 0.\n",
    "    for a in annotation:\n",
    "        for number, n in enumerate(train_netout):\n",
    "            grid_h, grid_w = n.shape[:2]\n",
    "            x, y, w, h = a[1:]\n",
    "            # here we have y and x that are normalized,so we are multiplying them by grid dims to make grid dims the units and know which col and row using int()\n",
    "            i = int(x * grid_w) # row\n",
    "            j = int(y * grid_h) # col\n",
    "            for b in range(len(n[j][i])):\n",
    "                # class value and objness\n",
    "                if np.all(train_netout[number][j][i][b][4:] == 1e-9) : # if all array éléments are 1e-9, to know if we have updating the data in this bbox , if yes we will pass to the second bbox(we have 3 bboxes)  \n",
    "                    train_netout[number][j][i][b][5+int(a[0])] = 1 # here we are adding a[0],to know wich class that has 1 (wich class is correct)\n",
    "                    train_netout[number][j][i][b][4] = 1 \n",
    "                # coords\n",
    "                encoded_x = x * grid_w - j\n",
    "                encoded_y = y * grid_h - i\n",
    "\n",
    "                if np.all(train_netout[number][j][i][b][:4] == 1e-9):\n",
    "                    encoded_w = np.log(w * net_w / anchors[number][2 * b + 0])\n",
    "                    encoded_h = np.log(h * net_h / anchors[number][2 * b + 1])\n",
    "                    train_netout[number][j][i][b][:4] = encoded_x, encoded_y, encoded_w, encoded_h\n",
    "                    break\n",
    "    # apply the _logit function to x,y,objness,classes to be then decoded using sigmoid function\n",
    "    for i in range(len(train_netout)):\n",
    "        grid_h, grid_w = train_netout[i].shape[:2]\n",
    "        train_netout[i][..., :2]  = _logit(train_netout[i][..., :2])\n",
    "        train_netout[i][..., 4:]  = _logit(train_netout[i][..., 4:]) \n",
    "        train_netout[i] = train_netout[i].reshape((1,grid_h, grid_w,np.multiply(train_netout[i].shape[2],train_netout[i].shape[3])))\n",
    "    return train_netout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79980ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:03.518587Z",
     "iopub.status.busy": "2023-03-12T14:40:03.518229Z",
     "iopub.status.idle": "2023-03-12T14:40:07.030297Z",
     "shell.execute_reply": "2023-03-12T14:40:07.029335Z"
    },
    "papermill": {
     "duration": 3.727105,
     "end_time": "2023-03-12T14:40:07.032820",
     "exception": false,
     "start_time": "2023-03-12T14:40:03.305715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 416,416\n",
    "encoded_train = [encode_annotations(annotation, nb_classes, anchors, HEIGHT, WIDTH) for annotation in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a286e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:07.438752Z",
     "iopub.status.busy": "2023-03-12T14:40:07.438375Z",
     "iopub.status.idle": "2023-03-12T14:40:08.180707Z",
     "shell.execute_reply": "2023-03-12T14:40:08.179663Z"
    },
    "papermill": {
     "duration": 0.946984,
     "end_time": "2023-03-12T14:40:08.183139",
     "exception": false,
     "start_time": "2023-03-12T14:40:07.236155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    " \n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score\n",
    " \n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    " \n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2] # number of grids in y,numbmer of grids in x\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1)) # -1 signifie les indexes qui sont restés(confience,class,...)\n",
    "    nb_class = netout[0].shape[-1] - 5 # will take 85 -5  (-5 pour ne pas calculer confience,...)\n",
    "    boxes = []\n",
    "    # \"...\" mean selecting all the dims,like doing map function and apply sigmoid to the first 2 éléments from each array(netout[..., :2] contient les coordonnées x et y de la boîte englobante prédite pour chaque grille de l'image d'entrée. )\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    # like doing map function apply sigmoid to the éléments from index 4 for each array\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    # we are adding a new axe because they haven't the same dim,netout[..., 4][..., np.newaxis] has the objness(probability of presence for an object), and netout[..., 5:] has scores of classes and multiply them to get the real scores\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    # If netout[..., 5:] > obj_thresh it will returns 1 and then multiplies it by netout[..., 5:],else it will returns 0 and multiplies it by netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        # actually here i did not like the names of variables,but the row variable contains in which column in the row we are in, and col variable contains in which row we are in the column\n",
    "        row = i / grid_w # we will then convert it to int ,so it will returns the same value grid_w times,and then it will returns 0 to repeat the same thing grid_h times\n",
    "        col = i % grid_w # we will then convert it to int, so it will returns numbers from 0-12 and repeat it grid_h times\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness <= obj_thresh): continue # skip the iterate if the objectness is lower or equal to 0.6\n",
    "            # first 4 elements are x, y, w, and h: x is representing the position (x) for the center of the bbox in the first col and first row (0,0)\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            # x is representing the relatif position of the center point in the bbox in term of the grid width(i don't mean the number of the grids in x) this mean we suppose that the image has 13 pixels and x is the position in the first grid. we are adding col to x to determine in which col the x is located,and then we are dividing by grid_w (number of grids in x) because the image will not necessary be 13 by 13 pixels, it can be anything so we normalize it to be compatible with all images(in correct_yolo_boxes function we will multiply it by the image width :here is 416)\n",
    "            # to understand it more ,if x = 0.5 and col = 0,that mean x is exactely in the center of the grid that is in col, when we are adding col(0) to x ,the result be 0.5 ,and then we will divid it by 13(first grid_w) to get the value that will be compatible with all images, and then we can multiply it by 416(width of our image)\n",
    "            # with another methode, if we multiply it by 416 that mean (col + x) / grid_w * 416 = 416/grid_w * col + 416/grid_w*x,here we are taking the width of each grid (416/grid_w) and multiply it by col to get the distance that precede the col where x is localted, and then add it to the width of the each grid multiply by x (position relative ini term of the width of each grid),when we multiply this mean that we will know what is the distance the procede the first point in the col and x, finaly we are adding this distances to get the real x .\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            # is the same of x but with y position\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            # anchors[1] the width is in index 0 ,anchors[1] is in index 2, and anchors[2] is in index 4, for that we used [2 * b + 0]\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            # [2 * b + 1] because the height is after 1 index from the width index\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h #unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    " \n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "        # we are calculation the offset(الازاحة) between the width of neural netword output and the new_image,and then dividing it by 2 because we want the image center point offset \n",
    "        # and then we are caculating the scale by dividing the new_w by the the width of the nn output\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w \n",
    "        # the same of x , but here we are calculating for y position\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        # calculation the coords by subtracting the offset from the coords of the point, and then divide the resulte by the scale to get the corect normalized value\n",
    "        # finally we multiply the result by the image dim,to get the real coords for the image\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    # define an interval ([a;b])\n",
    "\tx1, x2 = interval_a \n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1: # if interval_b is left of the interval_a ,so there is no intersections:will return 0\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1 # we taked the minimun value from(x2,x4) to know which is the end of the intersection,and # we are substractint x1 from the result because it's biggert than x3\n",
    "\telse:\n",
    "\t\tif x2 < x3: # if interval_b is right of the interval_a ,so there is no intersections:will return 0\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3 # we are substractint x3 from the result because it's biggert than x1\n",
    "\n",
    "# Calculating the amount of similarity between two bboxes\n",
    "def bbox_iou(box1, box2):\n",
    "    # Calculation the somme of intersection between bboxes \n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax]) # somme of intersections in x axis for each bbox\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax]) # somme of intersections in y axis for each bbox\n",
    "\tintersect = intersect_w * intersect_h  # calculating the area of the intersection\n",
    "    # calculation the width and the height of the bbox\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin \n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect # union(اتحاد) ,we are here calculation the union that is the somme of bboxes without the intersection\n",
    "    # return the percentage of the intersection between the two bboxes\n",
    "    # which is a value between 0 and 1, if it's 0 so there is no intersection,if it's 1 so there is a very high intersection\n",
    "\treturn float(intersect) / union \n",
    " \n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)# will stock how many classes for the first bbox in the detection.(it's not important to use the first one,because we want just know how many classes the nn can prediction\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        # np.argsort is used to sort the indexes of the classes by their scores,\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes]) # we are make the score negatif to sort them from the biggest to the smalest\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue # if the score of the class is 0 ,it will skip the iteration\n",
    "            for j in range(i+1, len(sorted_indices)): # will loop from i+1 to len(sorted_indices),we are adding one to i ,because we want to compare our bbox with the others bboxes\n",
    "                index_j = sorted_indices[j] # the bbox that we will compare it with the current bbox\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh: # if the percentage of the intersection is biggest or equal to nms_thresh\n",
    "                    boxes[index_j].classes[c] = 0 # we will give the bboxes that has a big similarity with this bbox 0.don't worry ,it will choose the one that has the biggest accuracy,because we sorted the scores from the biggest to the smalest\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape)\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    " \n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores\n",
    " \n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i]) # %s will take v_labels[i], (%.3f) is used to make the scores float with 3 numbers after the point,() we will write it in the axis to separate them\n",
    "        if v_labels[i] == 'mask':\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='green')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            pyplot.text(x1, y1, label, color='red')\n",
    "        elif v_labels[i] == 'no mask':\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            pyplot.text(x1, y1, label, color='red')\n",
    "        else:\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='yellow')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            pyplot.text(x1, y1, label, color='yellow')\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a233adad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:08.584978Z",
     "iopub.status.busy": "2023-03-12T14:40:08.584577Z",
     "iopub.status.idle": "2023-03-12T14:40:08.608609Z",
     "shell.execute_reply": "2023-03-12T14:40:08.607618Z"
    },
    "papermill": {
     "duration": 0.226733,
     "end_time": "2023-03-12T14:40:08.610671",
     "exception": false,
     "start_time": "2023-03-12T14:40:08.383938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'/kaggle/working/mask-detection-with-high-performcance-4/train/2018-11-06t054310z-1334124005-rc1be15a8050-rtrmadp-3-people-sexiest-man_jpg.rf.2d3a619df33eba59207163243a0a9172.jpg',\n",
       "       b'/kaggle/working/mask-detection-with-high-performcance-4/train/2018-11-06t054310z-1334124005-rc1be15a8050-rtrmadp-3-people-sexiest-man_jpg.rf.65c8e0c52055c3863de29d3e016f40d5.jpg',\n",
       "       b'/kaggle/working/mask-detection-with-high-performcance-4/train/2018-11-06t054310z-1334124005-rc1be15a8050-rtrmadp-3-people-sexiest-man_jpg.rf.9012d43bc5c0fb264bec26aa154920fa.jpg',\n",
       "       b'/kaggle/working/mask-detection-with-high-performcance-4/train/2018-11-06t054310z-1334124005-rc1be15a8050-rtrmadp-3-people-sexiest-man_jpg.rf.a52d4413fc9a579ef65fe5975ae2d441.jpg',\n",
       "       b'/kaggle/working/mask-detection-with-high-performcance-4/train/Africa-2_png_jpg.rf.298574a67620f52a1b613a6b2a930243.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_paths.batch(5).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cfda7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-12T14:40:09.055337Z",
     "iopub.status.busy": "2023-03-12T14:40:09.054973Z",
     "iopub.status.idle": "2023-03-12T14:40:09.320192Z",
     "shell.execute_reply": "2023-03-12T14:40:09.318594Z"
    },
    "papermill": {
     "duration": 0.468455,
     "end_time": "2023-03-12T14:40:09.322007",
     "exception": true,
     "start_time": "2023-03-12T14:40:08.853552",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/2129641883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "photo_filename = '/kaggle/input/testingofimages/Capture dcran 2023-02-24 011809.jpg'\n",
    "WIDTH, HEIGHT = 416,416\n",
    "class_threshold = 0.3\n",
    "# load picture with old dimensions\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n",
    "\n",
    "# Predict image\n",
    "yhat = model.predict(image)\n",
    "# Create boxes\n",
    "boxes = list()\n",
    "for i in range(3):\n",
    "    # decode the output of the network\n",
    "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)# yhat[i][0] 0 because it has 4 dims 1,?,?,3 so we take \n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n",
    "\n",
    "# suppress non-maximal boxes (make it small if you want to delete the duplicated bboxes)\n",
    "do_nms(boxes, 0.1)\n",
    "\n",
    "# define the labels (Filtered only the ones relevant for this task, which were used in pretraining the YOLOv3 model)\n",
    "labels = ['mask weared incorrect',\"mask\",\"no mask\"]\n",
    "\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "\n",
    "    print(v_labels[i], v_scores[i])\n",
    "\n",
    "# draw what we found\n",
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca748f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:01.883760Z",
     "iopub.status.busy": "2023-03-09T12:26:01.883283Z",
     "iopub.status.idle": "2023-03-09T12:26:02.914326Z",
     "shell.execute_reply": "2023-03-09T12:26:02.913330Z",
     "shell.execute_reply.started": "2023-03-09T12:26:01.883722Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert encoded_train into a rectangular list(list of arrays with same shape), because tensorflow is not compatible with non rectangulars arrays\n",
    "\n",
    "# 24 is ,(3 + 5)*3 first 3 is nb_classes,5 is coords and objness,and multipiled by 3 that is the number of bboxes for each grid\n",
    "zeros_array = [[np.zeros(s) for s in [(1,52, 52,24), (1,52, 52 ,24), (1,52, 52, 24)]] for _ in range(len(encoded_train))] \n",
    "for a,annotation in enumerate(encoded_train):\n",
    "    for e,e_t in enumerate(annotation):\n",
    "        zeros_array[a][e][:,:e_t.shape[1],:e_t.shape[1],:] = e_t\n",
    "encoded_train = zeros_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1cbfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:02.916959Z",
     "iopub.status.busy": "2023-03-09T12:26:02.916551Z",
     "iopub.status.idle": "2023-03-09T12:26:32.754656Z",
     "shell.execute_reply": "2023-03-09T12:26:32.753672Z",
     "shell.execute_reply.started": "2023-03-09T12:26:02.916921Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = tf.data.Dataset.from_tensor_slices(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a280a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:32.756811Z",
     "iopub.status.busy": "2023-03-09T12:26:32.756227Z",
     "iopub.status.idle": "2023-03-09T12:26:32.764614Z",
     "shell.execute_reply": "2023-03-09T12:26:32.763608Z",
     "shell.execute_reply.started": "2023-03-09T12:26:32.756771Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a90f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:32.767500Z",
     "iopub.status.busy": "2023-03-09T12:26:32.767070Z",
     "iopub.status.idle": "2023-03-09T12:26:32.776708Z",
     "shell.execute_reply": "2023-03-09T12:26:32.775838Z",
     "shell.execute_reply.started": "2023-03-09T12:26:32.767464Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train.shuffle(2000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81788c35",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning-YOLOV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e938f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:50.157540Z",
     "iopub.status.busy": "2023-03-09T12:26:50.156985Z",
     "iopub.status.idle": "2023-03-09T12:26:50.855089Z",
     "shell.execute_reply": "2023-03-09T12:26:50.854000Z",
     "shell.execute_reply.started": "2023-03-09T12:26:50.157496Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee64299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:50.857710Z",
     "iopub.status.busy": "2023-03-09T12:26:50.857008Z",
     "iopub.status.idle": "2023-03-09T12:26:56.232088Z",
     "shell.execute_reply": "2023-03-09T12:26:56.231122Z",
     "shell.execute_reply.started": "2023-03-09T12:26:50.857670Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo_model = load_model('/kaggle/input/yolov3-model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f6c05",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Use personne weights beacause it's close to our class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af703357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:56.234602Z",
     "iopub.status.busy": "2023-03-09T12:26:56.234229Z",
     "iopub.status.idle": "2023-03-09T12:26:56.251874Z",
     "shell.execute_reply": "2023-03-09T12:26:56.250915Z",
     "shell.execute_reply.started": "2023-03-09T12:26:56.234548Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the weights of the outputs\n",
    "weights1 = yolo_model.layers[-3].get_weights()\n",
    "weights2 = yolo_model.layers[-2].get_weights()\n",
    "weights3 = yolo_model.layers[-1].get_weights()\n",
    "\n",
    "# Create new weights and biases arrays\n",
    "new_weights1 = np.zeros([1, 1, 1024, 15+nb_classes*3]) #5*3+3*3 because we have 3 bboxes and 3 classes, bboxes has 4 values and we have also the objness \n",
    "new_weights2 = np.zeros([1, 1, 512, 15+nb_classes*3])\n",
    "new_weights3 = np.zeros([1, 1, 256, 15+nb_classes*3])\n",
    "new_bias1 = np.zeros([15+nb_classes*3])\n",
    "new_bias2 = np.zeros([15+nb_classes*3])\n",
    "new_bias3 = np.zeros([15+nb_classes*3])\n",
    "\n",
    "# bboxes indexes\n",
    "bbox1 = [0, 1, 2, 3, 4]\n",
    "bbox2 = [85, 86, 87, 88, 89]\n",
    "bbox3 = [170, 171, 172, 173, 174]\n",
    "\n",
    "# classes probabilities\n",
    "prob1 = [5 for _ in range(nb_classes)]\n",
    "prob2 = [90 for _ in range(nb_classes)]\n",
    "prob3 = [175 for _ in range(nb_classes)]\n",
    "\n",
    "# Create a set of indices to keep\n",
    "indices = bbox1+prob1+bbox2+prob2+bbox3+prob3 # we taked also the prob of the class,and we are writing the last value of each bbox 3 times because we have 3 classes\n",
    "\n",
    "# Fill in the new weights and biases arrays\n",
    "for i in range(len(indices)):\n",
    "    new_weights1[:, :, :, i] = weights1[0][:, :, :, indices[i]]\n",
    "    new_weights2[:, :, :, i] = weights2[0][:, :, :, indices[i]]\n",
    "    new_weights3[:, :, :, i] = weights3[0][:, :, :, indices[i]]\n",
    "    new_bias1[i] = weights1[1][indices[i]]\n",
    "    new_bias2[i] = weights2[1][indices[i]]\n",
    "    new_bias3[i] = weights3[1][indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c99d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:56.253924Z",
     "iopub.status.busy": "2023-03-09T12:26:56.253536Z",
     "iopub.status.idle": "2023-03-09T12:26:56.298781Z",
     "shell.execute_reply": "2023-03-09T12:26:56.297870Z",
     "shell.execute_reply.started": "2023-03-09T12:26:56.253884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new layers to adapt the model to your new data\n",
    "new_output1 = Conv2D(15+nb_classes*3, (1,1), activation='linear', padding='same')(yolo_model.layers[-6].output) # connected to LeakyReLU (the layer that was connected to the previous ouput)\n",
    "new_output2 = Conv2D(15+nb_classes*3, (1,1), activation='linear', padding='same')(yolo_model.layers[-5].output)\n",
    "new_output3 = Conv2D(15+nb_classes*3, (1,1), activation='linear', padding='same')(yolo_model.layers[-4].output)\n",
    "\n",
    "# Create a new model with ragged tensors as output\n",
    "yolo_model = Model(inputs=yolo_model.input, outputs=[new_output1, new_output2, new_output3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70322715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:56.301318Z",
     "iopub.status.busy": "2023-03-09T12:26:56.300960Z",
     "iopub.status.idle": "2023-03-09T12:26:56.312395Z",
     "shell.execute_reply": "2023-03-09T12:26:56.311483Z",
     "shell.execute_reply.started": "2023-03-09T12:26:56.301282Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the new weights and biases for the outputs\n",
    "yolo_model.layers[-3].set_weights([new_weights1, new_bias1])\n",
    "yolo_model.layers[-2].set_weights([new_weights2, new_bias2])\n",
    "yolo_model.layers[-1].set_weights([new_weights3, new_bias3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3593e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:56.314728Z",
     "iopub.status.busy": "2023-03-09T12:26:56.314312Z",
     "iopub.status.idle": "2023-03-09T12:26:56.321281Z",
     "shell.execute_reply": "2023-03-09T12:26:56.320222Z",
     "shell.execute_reply.started": "2023-03-09T12:26:56.314690Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_mse(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ff3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:56.323440Z",
     "iopub.status.busy": "2023-03-09T12:26:56.322755Z",
     "iopub.status.idle": "2023-03-09T12:26:56.340660Z",
     "shell.execute_reply": "2023-03-09T12:26:56.339587Z",
     "shell.execute_reply.started": "2023-03-09T12:26:56.323402Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mask(Model): \n",
    "    def __init__(self, model,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, opt, loss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.lloss = loss\n",
    "        self.opt = opt\n",
    "    \n",
    "    def train_step(self,batch, **kwargs):\n",
    "        X, y = batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_loss = tf.constant(0.0)\n",
    "            coords = self.model(X,training=True)\n",
    "            for i in range(len(coords)):\n",
    "                c = coords[i]\n",
    "                if i == 0:\n",
    "                    _, y = batch\n",
    "                    y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,0,:,:13,:13,:]\n",
    "                elif i == 1:\n",
    "                    _, y = batch\n",
    "                    y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,1,:,:26,:26,:]\n",
    "                else:\n",
    "                    _, y = batch\n",
    "                    y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,2,:,:52,:52,:]\n",
    "                batch_loss += self.lloss(tf.cast(y,tf.float32),tf.cast(c,tf.float32))   \n",
    "            grad = tape.gradient(batch_loss, self.model.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"regress_loss\":batch_loss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        batch_loss = tf.constant(0.0)\n",
    "        coords = self.model(X,training=False)\n",
    "        for i in range(len(coords)):\n",
    "            c = coords[i]\n",
    "            if i == 0:\n",
    "                _, y = batch\n",
    "                y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,0,:,:13,:13,:]\n",
    "            elif i == 1:\n",
    "                _, y = batch\n",
    "                y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,1,:,:26,:26,:]\n",
    "            else:\n",
    "                _, y = batch\n",
    "                y = tf.transpose(y, perm=[2,1, 0, 3, 4, 5])[0,2,:,:52,:52,:]\n",
    "            batch_loss += self.lloss(tf.cast(y,tf.float32),tf.cast(c,tf.float32))   \n",
    "        return {\"regress_loss\":batch_loss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d938da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:57.600504Z",
     "iopub.status.busy": "2023-03-09T12:26:57.600155Z",
     "iopub.status.idle": "2023-03-09T12:26:57.609596Z",
     "shell.execute_reply": "2023-03-09T12:26:57.608668Z",
     "shell.execute_reply.started": "2023-03-09T12:26:57.600474Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Mask(yolo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96389f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:58.151238Z",
     "iopub.status.busy": "2023-03-09T12:26:58.150874Z",
     "iopub.status.idle": "2023-03-09T12:26:58.373471Z",
     "shell.execute_reply": "2023-03-09T12:26:58.372515Z",
     "shell.execute_reply.started": "2023-03-09T12:26:58.151208Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d2b37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd274e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T12:26:58.762528Z",
     "iopub.status.busy": "2023-03-09T12:26:58.762179Z",
     "iopub.status.idle": "2023-03-09T12:26:58.767259Z",
     "shell.execute_reply": "2023-03-09T12:26:58.766272Z",
     "shell.execute_reply.started": "2023-03-09T12:26:58.762498Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batches_per_epoch = 184\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b895e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T16:02:09.105735Z",
     "iopub.status.busy": "2023-03-09T16:02:09.105345Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=1e-3,decay=lr_decay),list_mse)\n",
    "model.fit(train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe5206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T20:28:08.172936Z",
     "iopub.status.busy": "2023-03-08T20:28:08.172162Z",
     "iopub.status.idle": "2023-03-08T20:28:08.802137Z",
     "shell.execute_reply": "2023-03-08T20:28:08.801142Z",
     "shell.execute_reply.started": "2023-03-08T20:28:08.172896Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo_model.save('mask_yolo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad43a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T20:28:22.935537Z",
     "iopub.status.busy": "2023-03-08T20:28:22.935144Z",
     "iopub.status.idle": "2023-03-08T20:28:24.050060Z",
     "shell.execute_reply": "2023-03-08T20:28:24.048782Z",
     "shell.execute_reply.started": "2023-03-08T20:28:22.935494Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/working')\n",
    "\n",
    "!tar -czf /kaggle/working/mask_yolo.h5\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(r'mask_yolo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43475cc1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Real Time Mask Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf406a1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "from tensorflow import lite as tflite\n",
    "\n",
    "# output_details = interpreter.get_output_details()\n",
    "yolo_model = load_model('mask_model.h5')\n",
    "\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "# in this code i changed x = (col + x) / grid_w to y = (row + x) / grid_w, and also in y , because because row is in x\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    " \n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score\n",
    " \n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    " \n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "#     netout = netout.numpy()\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    " \n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    " \n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union\n",
    " \n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "\n",
    "def load_image_pixels(image, shape):\n",
    "    height, width, _ = image.shape\n",
    "    # load the image with the required size\n",
    "    image = cv2.resize(image, shape)\n",
    "    # convert to numpy array\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = image[np.newaxis, ...]\n",
    "    return image, width, height\n",
    "\n",
    " \n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores\n",
    " \n",
    "# draw all results\n",
    "def draw_boxes(image, v_boxes, v_labels, v_scores):\n",
    "    # draw each box and label on the image\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        label = v_labels[i]\n",
    "        score = v_scores[i]\n",
    "        if label == 'mask':\n",
    "            # draw the box\n",
    "            cv2.rectangle(image, (box.xmin, box.ymin), (box.xmax, box.ymax), (0, 255, 0), 1)\n",
    "            # draw the label and score\n",
    "            text = f\"{label} ({score:.3f})\"\n",
    "            cv2.putText(image, text, (box.xmin, box.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "        elif label == 'no mask':\n",
    "            # draw the box\n",
    "            cv2.rectangle(image, (box.xmin, box.ymin), (box.xmax, box.ymax), (255, 0, 0), 1)\n",
    "            # draw the label and score\n",
    "            text = f\"{label} ({score:.3f})\"\n",
    "            cv2.putText(image, text, (box.xmin, box.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 1)\n",
    "        else:\n",
    "            # draw the box\n",
    "            cv2.rectangle(image, (box.xmin, box.ymin), (box.xmax, box.ymax), (255, 255, 0), 1)\n",
    "            # draw the label and score\n",
    "            text = f\"{label} ({score:.3f})\"\n",
    "            cv2.putText(image, text, (box.xmin, box.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 0), 1)\n",
    "        \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()          # read from camera\n",
    "    WIDTH, HEIGHT = 416,416\n",
    "    class_threshold = 0.6\n",
    "    # load picture with old dimensions\n",
    "    image, image_w, image_h = load_image_pixels(frame, (WIDTH, HEIGHT))\n",
    "    \n",
    "    yhat = yolo_model.predict(image)\n",
    "\n",
    "    # Create boxes\n",
    "    boxes = list()\n",
    "    for i in range(3):\n",
    "        # decode the output of the network\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)# yhat[i][0] 0 because it has 4 dims 1,?,?,3 so we take \n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, 0.1)\n",
    "\n",
    "    # define the labels (Filtered only the ones relevant for this task, which were used in pretraining the YOLOv3 model)\n",
    "    labels = ['mask weared incorrect',\"mask\",\"no mask\"]\n",
    "\n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "\n",
    "    # summarize what we found\n",
    "    for i in range(len(v_boxes)):\n",
    "\n",
    "        print(v_labels[i], v_scores[i])\n",
    "\n",
    "    # draw what we found\n",
    "    draw_boxes(frame, v_boxes, v_labels, v_scores)\n",
    "\n",
    "    cv2.imshow('frame',frame)         # show image\n",
    "    if cv2.waitKey(10) == ord('q'):  # wait a bit, and see keyboard press\n",
    "        break                        # if q pressed, quit\n",
    "\n",
    "# release things before quiting\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.405051,
   "end_time": "2023-03-12T14:40:12.899745",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-12T14:39:09.494694",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
